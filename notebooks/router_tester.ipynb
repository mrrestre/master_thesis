{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.router import Router\n",
    "from config.supported_llms import SupportedLLMs\n",
    "from testdata.email import EMAIL\n",
    "\n",
    "router = Router()\n",
    "output = router.route_input(EMAIL)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: client=<gen_ai_hub.proxy.native.openai.clients.ChatCompletions object at 0x14e8c6f90> async_client=<gen_ai_hub.proxy.native.openai.clients.AsyncChatCompletions object at 0x14e8d6510> model_name='gpt-4o' temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********') n=1 top_p=1.0 max_tokens=256 proxy_client=GenAIHubProxyClient(base_url=None, auth_url=None, client_id=None, client_secret=None, resource_group=None, ai_core_client=<ai_core_sdk.ai_core_v2_client.AICoreV2Client object at 0x14dc3cc20>) deployment_id='d9b97a453fb3ed0e' config_name='oliver-model-gpt-4o' config_id='3dfeba73-9b75-4d18-864e-c27b22eb0d0e' proxy_model_name='gpt-4o'\n",
      "Structured LLM: first=RunnableBinding(bound=ChatOpenAI(client=<gen_ai_hub.proxy.native.openai.clients.ChatCompletions object at 0x14e8c6f90>, async_client=<gen_ai_hub.proxy.native.openai.clients.AsyncChatCompletions object at 0x14e8d6510>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), n=1, top_p=1.0, max_tokens=256, proxy_client=GenAIHubProxyClient(base_url=None, auth_url=None, client_id=None, client_secret=None, resource_group=None, ai_core_client=<ai_core_sdk.ai_core_v2_client.AICoreV2Client object at 0x14dc3cc20>), deployment_id='d9b97a453fb3ed0e', config_name='oliver-model-gpt-4o', config_id='3dfeba73-9b75-4d18-864e-c27b22eb0d0e', proxy_model_name='gpt-4o'), kwargs={'response_format': <class '__main__.RouterOutputModel'>, 'ls_structured_output_format': {'kwargs': {'method': 'json_schema'}, 'schema': {'type': 'function', 'function': {'name': 'RouterOutputModel', 'description': 'Analyze the unread email and route it according to its content.', 'parameters': {'properties': {'reasoning': {'description': 'Step-by-step reasoning behind the classification.', 'type': 'string'}, 'classification': {'description': \"The classification of an email: 'ignore' for irrelevant emails, 'notify' for important information that doesn't need a response, 'respond' for emails that need a reply\", 'enum': ['ignore', 'respond', 'notify'], 'type': 'string'}}, 'required': ['reasoning', 'classification'], 'type': 'object'}}}}}, config={}, config_factories=[]) middle=[] last=RunnableBinding(bound=RunnableLambda(...), kwargs={}, config={}, config_factories=[], custom_output_type=<class '__main__.RouterOutputModel'>)\n",
      "Email Text: \n",
      "Hi Joe,\n",
      "\n",
      "Hope you're doing well. I wanted to check if youâ€™re available next Thursday for a meeting. If so, let me know what time works best for you, and we can get something scheduled.\n",
      "\n",
      "Looking forward to your reply.\n",
      "\n",
      "Best,  \n",
      "Bertha\n",
      "\n",
      "Error invoking structured_llm: 'NoneType' object has no attribute 'beta'\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from gen_ai_hub.proxy.langchain import init_llm\n",
    "from pydantic import BaseModel, Field\n",
    "from testdata.email import EMAIL\n",
    "\n",
    "\n",
    "class RouterOutputModel(BaseModel):\n",
    "    \"\"\"Analyze the unread email and route it according to its content.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"Step-by-step reasoning behind the classification.\"\n",
    "    )\n",
    "    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
    "        description=\"The classification of an email: 'ignore' for irrelevant emails, \"\n",
    "        \"'notify' for important information that doesn't need a response, \"\n",
    "        \"'respond' for emails that need a reply\",\n",
    "    )\n",
    "\n",
    "llm = init_llm(\"gpt-4o\")\n",
    "if llm is None:\n",
    "    raise ValueError(\"LLM initialization failed! Check API key or `gen_ai_hub` installation.\")\n",
    "\n",
    "print(f\"LLM initialized: {llm}\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(RouterOutputModel)\n",
    "\n",
    "print(f\"Structured LLM: {structured_llm}\")\n",
    "\n",
    "email_text = EMAIL.get(\"body\", \"No email content provided.\")\n",
    "print(f\"Email Text: {email_text}\")  # Debugging\n",
    "\n",
    "prompt = f\"Analyze the following email and classify it:\\n\\n{email_text}\"\n",
    "\n",
    "try:\n",
    "    output = structured_llm.invoke(prompt)\n",
    "    print(f\"Model Output: {output}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking structured_llm: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "react-agent-CUxtcVGL-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
